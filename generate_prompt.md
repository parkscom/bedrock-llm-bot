초기 챗봇 설정 및 기본 응답
=======
- "Slack 챗봇을 만들고 싶어. 이름은 '@hellochat'이야."
- "AWS Lambda를 기반으로 Python을 사용해서 구성해줘. slack_bolt 라이브러리를 사용하고 싶어."
- "봇이 멘션되면 간단한 인사 메시지를 보내도록 해줘."
- "모든 답변은 멘션된 메시지의 스레드에 달리도록 해줘. 새 멘션이면 새 스레드를 시작하고, 기존 스레드면 거기에 이어서 답변해줘."

Bedrock LLM 연동
=======
- "이제 봇의 답변을 Amazon Bedrock LLM (예: Claude 3 Sonnet)을 사용해서 생성하도록 수정해줘."
- "사용자의 질문을 LLM에 전달하고, LLM의 응답을 Slack으로 보내도록 해줘."
- "LLM 호출 시 필요한 환경 변수 (모델 ID, AWS 리전)와 IAM 권한에 대해서도 고려해줘."

대화 맥락 유지 (스레드 내용 활용)
=======
- "스레드 내에서 대화가 이어질 경우, 이전 대화 내용을 가져와서 LLM 프롬프트에 포함시켜줘. 그래야 LLM이 맥락에 맞는 답변을 할 수 있어."
- "Slack의 conversations.replies API를 사용해서 스레드 메시지를 가져오고, 이걸 LLM이 이해하기 쉬운 JSON 타임라인 형식 (예: [{"from": "user", "message": "..."}, {"from": "bot", "message": "..."}])으로 만들어줘."

시스템 프롬프트 외부화 및 로딩
=======
- "봇의 역할과 행동 지침을 정의하는 '시스템 프롬프트'를 사용하고 싶어."
- "이 시스템 프롬프트를 외부 텍스트 파일에서 읽어오도록 해줘. 파일 이름은 봇의 User ID를 기반으로 동적으로 결정되게 해줘 (예: system_prompt_U123ABC.txt)."
- "만약 해당 시스템 프롬프트 파일이 없거나 비어있으면, 사용자에게 설정이 필요하다고 안내하는 메시지를 보내줘."
- "생성된 LLM 프롬프트에는 이 시스템 프롬프트 내용, 대화 타임라인 JSON, 그리고 사용자의 최신 질문이 모두 포함되어야 해."

사용자 경험 개선
=======
- "LLM 응답 생성에 시간이 걸릴 수 있으니, 사용자에게 '잠시만 기다려주세요...' 같은 임시 대기 메시지를 먼저 보내줘."
- "LLM 답변이 완료되면, 이전에 보냈던 임시 대기 메시지는 삭제해줘."
- "LLM 답변 생성에 실제로 걸린 시간을 로그로 남겨줘."

안정성 및 실행 환경
=======
- "Slack에서 이벤트를 재시도할 경우 동일한 메시지가 여러 번 처리될 수 있으니, 이벤트 ID를 기반으로 중복 처리를 방지하는 로직을 추가해줘."
- "이 코드가 로컬 PC 환경(테스트 및 개발용)과 AWS Lambda 환경(배포용) 양쪽에서 모두 실행될 수 있도록 구성해줘."
- "로컬 실행 시에는 간단한 HTTP 서버를 사용해서 Lambda 환경을 시뮬레이션하고, ngrok을 통해 Slack 이벤트를 받을 수 있게 해줘."
- "로컬 서버에서 'Broken pipe' 에러가 발생하지 않도록, Slack 요청 수신 시 즉시 200 OK 응답을 보내고 실제 작업은 백그라운드 스레드에서 처리하도록 해줘."

최종 코드 검토 및 다듬기
=======
- "LLM 응답이 JSON 형식이 아닌 일반 텍스트로 나오도록 프롬프트를 수정해줘."
